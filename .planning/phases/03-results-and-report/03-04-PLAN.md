---
phase: 03-results-and-report
plan: 04
type: execute
wave: 3
depends_on: ["03-03"]
files_modified:
  - src/components/report/bubble-chart.tsx
  - src/components/report/latency-chart.tsx
  - src/components/report/cost-chart.tsx
  - src/components/report/cost-calculator.tsx
  - src/components/report/error-analysis.tsx
  - src/components/report/raw-runs.tsx
  - src/components/report/pdf-export-button.tsx
  - src/types/html2pdf.d.ts
  - src/app/report/[token]/page.tsx
  - package.json
autonomous: true

must_haves:
  truths:
    - "Report displays bubble chart (X=cost, Y=accuracy, size=P95 latency, opacity=consistency)"
    - "Report displays P95 latency comparison bar chart"
    - "Report displays cost per run bar chart"
    - "Report includes cost calculator with daily volume slider and model comparison dropdown"
    - "Report shows field-level error diffs per model with aggregated error patterns"
    - "Report shows expandable raw run data per model with pass/fail and JSON output"
    - "Report is exportable as PDF via client-side html2pdf.js"
  artifacts:
    - path: "src/components/report/bubble-chart.tsx"
      provides: "SVG bubble chart (cost vs accuracy, size=P95, opacity=consistency)"
      exports: ["BubbleChart"]
    - path: "src/components/report/latency-chart.tsx"
      provides: "SVG P95 latency bar chart"
      exports: ["LatencyChart"]
    - path: "src/components/report/cost-chart.tsx"
      provides: "SVG cost per run bar chart"
      exports: ["CostChart"]
    - path: "src/components/report/cost-calculator.tsx"
      provides: "Interactive cost calculator with volume slider"
      exports: ["CostCalculator"]
    - path: "src/components/report/error-analysis.tsx"
      provides: "Field-level error diffs and aggregated error patterns"
      exports: ["ErrorAnalysis"]
    - path: "src/components/report/raw-runs.tsx"
      provides: "Expandable per-model raw run data"
      exports: ["RawRuns"]
    - path: "src/components/report/pdf-export-button.tsx"
      provides: "Client-side PDF export via html2pdf.js"
      exports: ["PdfExportButton"]
  key_links:
    - from: "src/app/report/[token]/page.tsx"
      to: "src/components/report/bubble-chart.tsx"
      via: "Import and render in charts section"
      pattern: "BubbleChart"
    - from: "src/app/report/[token]/page.tsx"
      to: "src/components/report/error-analysis.tsx"
      via: "Import and render in analysis section"
      pattern: "ErrorAnalysis"
    - from: "src/components/report/pdf-export-button.tsx"
      to: "html2pdf.js"
      via: "Dynamic import of browser-only library"
      pattern: "import.*html2pdf"
---

<objective>
Add all remaining report components: three SVG chart visualizations, interactive cost calculator, field-level error analysis, expandable raw run data, and PDF export. Wire everything into the report page created in Plan 03.

Purpose: Completes the full report experience (RPT-03 through RPT-10, RPT-12). After this plan, the report page is feature-complete.

Output: 7 new component files, 1 type declaration, updated report page, html2pdf.js dependency installed.
</objective>

<execution_context>
@/Users/lukelibraro/.claude/get-shit-done/workflows/execute-plan.md
@/Users/lukelibraro/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-results-and-report/03-RESEARCH.md

# Report page created in Plan 03 (to be modified)
@src/app/report/[token]/page.tsx

# Data layer from Plan 01
@src/types/report.ts
@src/lib/report/aggregate.ts
@src/lib/report/error-patterns.ts

# Database types for raw runs
@src/types/database.ts
@src/types/benchmark.ts

# Model info for provider colors
@src/lib/config/models.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: SVG chart components (bubble, latency, cost) and cost calculator</name>
  <files>
    src/components/report/bubble-chart.tsx
    src/components/report/latency-chart.tsx
    src/components/report/cost-chart.tsx
    src/components/report/cost-calculator.tsx
  </files>
  <action>
All four components are `"use client"` (for hover tooltips on charts, and slider interaction on calculator).

**Provider color map** (use in all charts for consistent model coloring):
Define a `PROVIDER_COLORS` map at the top of each chart (or in a shared constant): `{ openai: "#10A37F", anthropic: "#D4A574", google: "#4285F4", "meta-llama": "#0668E1", qwen: "#6366F1", mistralai: "#FF7000", "x-ai": "#FFFFFF", nvidia: "#76B900" }`. Fall back to `#6B7280` for unknown providers.

**A. `bubble-chart.tsx` (RPT-03):**
- Props: `data: Array<{ modelName: string; cost: number; accuracy: number; p95: number; spread: number; provider: string }>`
- SVG viewBox: `0 0 600 400`, use `className="w-full h-auto"` for responsive scaling
- Padding: top=30, right=40, bottom=50, left=60
- Axes:
  - X-axis (bottom): Cost per run ($). Scale from 0 to max cost with 5 tick marks. Label: "Cost per Run ($)"
  - Y-axis (left): Accuracy (%). Scale from min accuracy-5 (floored to nearest 5) to 100. Label: "Field Accuracy (%)"
- Data points: `<circle>` elements
  - cx = scaleX(cost), cy = scaleY(accuracy)
  - r = 8 + (p95 / maxP95) * 24 (range 8-32px)
  - fill = provider color, fillOpacity = max(0.3, 1 - spread/50) (consistent models are more opaque)
  - stroke = provider color, strokeWidth = 1.5
- Grid lines: light horizontal dashed lines at each Y tick (`stroke="#333" strokeDasharray="4 4"`)
- Hover tooltip: use a `<title>` SVG element inside each circle for native browser tooltip: "{modelName}\nAccuracy: {accuracy}%\nCost: ${cost}\nP95: {p95}ms\nSpread: Â±{spread}%"
- No foreignObject (breaks in PDF export per research Pitfall 4). Keep SVG simple.
- Axis labels as SVG `<text>` elements with `fill="var(--color-text-muted)"` (or use the hex value from the Tailwind theme -- #6B7280 or similar).

**B. `latency-chart.tsx` (RPT-04):**
- Props: `data: Array<{ modelName: string; p95: number; provider: string }>`
- Horizontal bar chart (models on Y-axis, P95 latency on X-axis)
- SVG viewBox calculated dynamically: width=600, height=max(200, data.length * 36 + 60)
- Each bar: `<rect>` with height=24, width proportional to p95/maxP95, fill=provider color, rx=4 for rounded corners
- Value label at end of each bar: "{p95}ms" in small text
- Model name labels on Y-axis (left-aligned)
- X-axis: latency in ms with tick marks
- Bars sorted by p95 ascending (fastest at top)

**C. `cost-chart.tsx` (RPT-05):**
- Props: `data: Array<{ modelName: string; costPerRun: number; provider: string }>`
- Horizontal bar chart (same layout pattern as latency chart)
- Bars sorted by costPerRun ascending (cheapest at top)
- Value label: "${costPerRun}" formatted to 4-6 decimal places
- Free models ($0.00) get a "FREE" badge instead of bar

**D. `cost-calculator.tsx` (RPT-08):**
- Props: `models: ModelSummary[]`, `recommendedModelId: string | null`
- State (all local, per research Pitfall 6):
  - `dailyVolume`: number (range slider, 10-10000, step 10, default 100)
  - `comparisonModelId`: string (dropdown, defaults to most expensive model)
- Calculations:
  - `monthlyCostRecommended = recommended.costPerRun * dailyVolume * 30`
  - `monthlyCostComparison = comparison.costPerRun * dailyVolume * 30`
  - `monthlySavings = monthlyCostComparison - monthlyCostRecommended`
  - `yearlySavings = monthlySavings * 12`
- Render:
  - "Cost Calculator" section heading
  - Slider with label: "Daily API calls: {dailyVolume}" (use range input with accent-ember)
  - Quick-set buttons: 100, 500, 1000, 5000 calls/day
  - Model comparison dropdown (`<select>` with all models except recommended)
  - Two cost cards side by side:
    - Recommended: model name, monthly cost, "Recommended" badge
    - Comparison: model name, monthly cost
  - Savings callout card: "Save ${monthlySavings}/month (${yearlySavings}/year)" in green-tinted card, only shown if savings > 0
  - If recommended is MORE expensive, show "Costs ${-monthlySavings}/month more" in amber-tinted card
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. All four files export their documented components
3. All use `"use client"` directive
4. Charts use only simple SVG elements (circle, rect, line, text, g) -- no foreignObject, no clipPath
5. Charts have `<title>` tooltips on data elements
6. Cost calculator state is entirely local (no prop callbacks)
  </verify>
  <done>Three SVG chart components render cost/accuracy bubble chart, P95 latency bars, and cost comparison bars. Cost calculator provides interactive volume-based cost projections. Fulfills RPT-03, RPT-04, RPT-05, RPT-08.</done>
</task>

<task type="auto">
  <name>Task 2: Error analysis, raw runs, and PDF export components</name>
  <files>
    src/components/report/error-analysis.tsx
    src/components/report/raw-runs.tsx
    src/components/report/pdf-export-button.tsx
    src/types/html2pdf.d.ts
  </files>
  <action>
**A. `error-analysis.tsx` (RPT-06, RPT-07)** -- `"use client"` component:

- Props: `models: ModelSummary[]`, `errorPatterns: ErrorPattern[]`, `runsByModel: Record<string, Array<{ field_errors: Array<{ fieldPath: string; expected: string; actual: string }>; exact_match: boolean }>>`

Two sections in this component:

**Section 1: Aggregated Error Patterns (RPT-07):**
- Show top error patterns sorted by percentage (from `errorPatterns` prop)
- Each pattern rendered as a card:
  - "{modelName} misses `{fieldPath}` {percentage}% of the time"
  - Expected vs actual values shown in a mini diff: expected in green, actual in red
  - Occurrence count: "{occurrences}/{totalRuns} runs"
- Limit to top 15 patterns. If more exist, show "and {N} more patterns" link that expands to show all
- Empty state: "All models achieved perfect field extraction!" with a checkmark icon

**Section 2: "Where It Missed" per-model field diffs (RPT-06):**
- Collapsible accordion per model (use `<details>`/`<summary>` for zero-JS compatibility)
- Each model section:
  - Model name + accuracy badge + number of field errors
  - Expandable content shows a table of field errors:
    | Field Path | Expected | Actual | Occurrences |
  - Expected values in `text-green-400 bg-green-400/10 px-1 rounded font-mono text-xs`
  - Actual values in `text-red-400 bg-red-400/10 px-1 rounded font-mono text-xs`
  - Missing fields (actual is empty/null): show "MISSING" badge in red
  - Extra fields (expected is empty): show "EXTRA" badge in amber

**B. `raw-runs.tsx` (RPT-10)** -- `"use client"` component:

- Props: `models: ModelSummary[]`, `runsByModel: Record<string, BenchmarkRun[]>`
- Collapsible accordion per model using useState (not `<details>`, since we want to lazy-render content):
  - Summary row: Model name, runs completed/attempted, accuracy%
  - Expanded content: table of individual runs:
    | Run # | Image | Status | Exact Match | Field Accuracy | Response Time | Cost |
  - Status badges: "complete" (green), "failed" (red), "skipped" (gray)
  - Exact match: checkmark (green) or X (red)
  - Expandable JSON diff per run: show output_json in a `<pre>` block with `bg-surface text-text-secondary font-mono text-xs p-3 rounded overflow-x-auto max-h-48 overflow-y-auto`
- Only expand one model at a time (clicking another collapses the current)
- Show warning if output_json data is large

**C. `pdf-export-button.tsx` (RPT-12)** -- `"use client"` component:

- Props: `filename?: string` (default: "benchmark-report.pdf")
- State: `exporting: boolean`
- On click:
  1. Set exporting=true
  2. Dynamic import: `const html2pdf = (await import("html2pdf.js")).default`
  3. Get element: `document.getElementById("report-content")` (the id on the report page wrapper div)
  4. Call html2pdf with options:
     ```
     margin: [10, 10, 10, 10],
     filename,
     image: { type: "jpeg", quality: 0.95 },
     html2canvas: { scale: 2, useCORS: true, backgroundColor: "#0A0A0B" },
     jsPDF: { unit: "mm", format: "a4", orientation: "portrait" },
     pagebreak: { mode: ["avoid-all", "css", "legacy"] }
     ```
  5. Set exporting=false in finally block
- Render: Button with FileDown icon (lucide-react), text "Export PDF" / "Exporting...", disabled when exporting
- Same button style as ShareButton (secondary variant)

**D. `src/types/html2pdf.d.ts`** -- minimal type declaration:
```typescript
declare module "html2pdf.js" {
  interface Html2PdfOptions {
    margin?: number | number[];
    filename?: string;
    image?: { type?: string; quality?: number };
    html2canvas?: Record<string, unknown>;
    jsPDF?: Record<string, unknown>;
    pagebreak?: { mode?: string[] };
  }

  interface Html2PdfInstance {
    set(options: Html2PdfOptions): Html2PdfInstance;
    from(element: HTMLElement): Html2PdfInstance;
    save(): Promise<void>;
  }

  function html2pdf(): Html2PdfInstance;
  export default html2pdf;
}
```

**Install html2pdf.js:**
Run `npm install html2pdf.js` before creating the components.
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. `npm run build` succeeds
3. All four files exist and export their documented components/types
4. html2pdf.js is in package.json dependencies
5. Error analysis shows aggregated patterns and per-model field diffs
6. Raw runs has collapsible accordion per model
7. PDF export button uses dynamic import for html2pdf.js
  </verify>
  <done>Error analysis shows field-level diffs and aggregated patterns. Raw runs expand per model. PDF export generates A4 PDF from report DOM. Fulfills RPT-06, RPT-07, RPT-10, RPT-12.</done>
</task>

<task type="auto">
  <name>Task 3: Wire all components into report page</name>
  <files>src/app/report/[token]/page.tsx</files>
  <action>
Modify `src/app/report/[token]/page.tsx` to import and render all components created in Tasks 1 and 2:

1. **Import all new components:**
   - `BubbleChart` from `@/components/report/bubble-chart`
   - `LatencyChart` from `@/components/report/latency-chart`
   - `CostChart` from `@/components/report/cost-chart`
   - `CostCalculator` from `@/components/report/cost-calculator`
   - `ErrorAnalysis` from `@/components/report/error-analysis`
   - `RawRuns` from `@/components/report/raw-runs`
   - `PdfExportButton` from `@/components/report/pdf-export-button`
   - `aggregateErrorPatterns` from `@/lib/report/error-patterns`

2. **Prepare chart data** in the server component (before JSX):
   - Build `bubbleData` array from `reportData.models`: map each model to `{ modelName, cost: costPerRun, accuracy, p95: p95Latency, spread, provider }`
   - Build `latencyData` array: map each model to `{ modelName, p95: p95Latency, provider }`
   - Build `costData` array: map each model to `{ modelName, costPerRun, provider }`
   - Build `runsByModel` record: group the raw benchmark runs by model_id as `Record<string, BenchmarkRun[]>` -- query raw runs from Supabase and group them
   - Call `aggregateErrorPatterns(reportData.models, runsByModel)` to get error patterns

3. **Add PdfExportButton** next to ShareButton in the ReportHeader action row. Pass the PdfExportButton as a child or add it directly in the page layout next to the header.

4. **Render sections in order** inside the `report-content` div:
   ```
   <ReportHeader ... />
   <PdfExportButton />  (next to share button)

   <section> <!-- Recommendation -->
     <RecommendationCard ... />
   </section>

   <section> <!-- Rankings -->
     <h2>Model Rankings</h2>
     <RankedTable ... />
   </section>

   <section> <!-- Visualizations -->
     <h2>Visualizations</h2>
     <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
       <div className="bg-surface-raised rounded-xl p-5 border border-surface-border">
         <h3>Accuracy vs Cost</h3>
         <BubbleChart data={bubbleData} />
       </div>
       <div className="bg-surface-raised rounded-xl p-5 border border-surface-border">
         <h3>P95 Latency</h3>
         <LatencyChart data={latencyData} />
       </div>
     </div>
     <div className="bg-surface-raised rounded-xl p-5 border border-surface-border">
       <h3>Cost per Run</h3>
       <CostChart data={costData} />
     </div>
   </section>

   <section> <!-- Error Analysis -->
     <h2>Where It Missed</h2>
     <ErrorAnalysis models={reportData.models} errorPatterns={errorPatterns} runsByModel={runsByModelSerialized} />
   </section>

   <section> <!-- Cost Calculator -->
     <h2>Cost Calculator</h2>
     <CostCalculator models={reportData.models} recommendedModelId={reportData.recommendedModelId} />
   </section>

   <section> <!-- Raw Data -->
     <h2>Raw Run Data</h2>
     <RawRuns models={reportData.models} runsByModel={runsByModelSerialized} />
   </section>
   ```

5. **Handle raw run data serialization** carefully per research Pitfall 7:
   - For ErrorAnalysis, pass only the field_errors and exact_match from each run (strip output_json)
   - For RawRuns, pass full run data BUT strip output_json from initial load -- add a note that full JSON output is available in the expandable section
   - Actually, for simplicity in MVP: pass all run data. The max is ~750 rows. If it becomes a performance issue, it can be optimized in a gap closure plan.

6. **Section headings** should use consistent styling: `text-xl font-semibold text-text-primary`

7. **RPT-09 (OpenRouter baseline):** Per research finding, OpenRouter does NOT expose per-model latency baselines. Instead, add a brief note in the cost chart section: "Costs reflect your benchmark results using OpenRouter API pricing." This honestly communicates the data source without inventing fake baselines.
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. `npm run build` succeeds
3. Report page imports all 7 new components
4. Report page renders sections: recommendation, rankings, visualizations (3 charts), error analysis, cost calculator, raw data
5. PdfExportButton appears in the header action area
6. Chart data is prepared server-side from reportData.models
7. Error patterns are computed from runsByModel data
  </verify>
  <done>Report page is feature-complete with all components wired in: recommendation, ranked table, 3 charts, error analysis, cost calculator, raw runs, share button, and PDF export. Fulfills RPT-01 through RPT-12.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes
2. `npm run build` succeeds
3. Report page renders all sections: header, recommendation, table, 3 charts, error analysis, calculator, raw runs
4. Bubble chart renders SVG circles with correct axes
5. Latency and cost bar charts render horizontal bars
6. Cost calculator slider updates projections reactively
7. Error patterns show model-field failure frequencies
8. Raw runs expand per model
9. PDF export generates downloadable PDF from report DOM
10. html2pdf.js installed and type declaration present
</verification>

<success_criteria>
- Bubble chart shows cost vs accuracy with P95 size and consistency opacity (RPT-03)
- P95 latency bar chart compares models (RPT-04)
- Cost per run bar chart compares models (RPT-05)
- Error analysis shows field-level diffs per model (RPT-06) and aggregated patterns (RPT-07)
- Cost calculator projects monthly costs with volume slider and model comparison (RPT-08)
- RPT-09 handled via cost-based comparison note (OpenRouter has no latency baseline API)
- Raw run data expandable per model (RPT-10)
- PDF export downloads report as A4 PDF with dark background (RPT-12)
- All charts use simple SVG primitives (no foreignObject, no charting library)
- All components use existing Tailwind dark-warm palette
</success_criteria>

<output>
After completion, create `.planning/phases/03-results-and-report/03-04-SUMMARY.md`
</output>
